import { loadEnvFile } from 'node:process';
import { GoogleGenAI, Modality } from "@google/genai";
import type { MultipartFile } from '@fastify/multipart';
import { GenerateVisualizationParams } from '../types.js';
import { buildVisualizationPrompt, buildInfluencePrompt, buildFurniturePrompt } from '../prompts/visualization.prompt.js';

if (!process.env.K_SERVICE) {
	loadEnvFile();
}

// const isDev = process.env.NODE_ENV === 'development'

// if (isDev) {

//   const API_KEY = process.env.API_KEY;
//   if (!API_KEY) {
//     throw new Error("API_KEY environment variable not set");
//   }
// }

// const ai = new GoogleGenAI(isDev ? { apiKey: process.env.API_KEY } : {});

const API_KEY = process.env.API_KEY;
if (!API_KEY) {
	throw new Error("API_KEY environment variable not set");
}


const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

const bufferToGenerativePart = (file: MultipartFile & { buffer: Buffer }) => {
	const base64Data = file.buffer.toString('base64');
	return {
		inlineData: { data: base64Data, mimeType: file.mimetype },
	};
};

export const generateVisualization = async (params: GenerateVisualizationParams): Promise<string> => {
	const {
		roomImage,
		roomType,
		stylePreset,
		moodBoardImages,
		furnitureImage,
		textPrompt,
		styleInfluence,
		isRefinement,
		previousResultImage,
	} = params;

	const model = 'gemini-2.5-flash-image';

	const influencePrompt = buildInfluencePrompt(moodBoardImages.length, styleInfluence, stylePreset.name);
	const furniturePrompt = buildFurniturePrompt(!!furnitureImage, roomType);

	const fullPrompt = buildVisualizationPrompt({
		isRefinement: Boolean(isRefinement),
		roomType,
		stylePresetName: stylePreset.name,
		influencePrompt,
		textPrompt,
		furniturePrompt,
	});

	const roomImagePart = bufferToGenerativePart(roomImage);

	const moodBoardParts = moodBoardImages.map(bufferToGenerativePart);

	const parts: Array<{ inlineData: { data: string; mimeType: string } } | { text: string }> = [
		roomImagePart,
	];

	// Add previous result image for refinement context
	if (isRefinement && previousResultImage) {
		const previousResultPart = bufferToGenerativePart(previousResultImage);
		parts.push(previousResultPart);
	}

	// Add the prompt
	parts.push({ text: fullPrompt });

	// Add mood board images
	parts.push(...moodBoardParts);

	if (furnitureImage) {
		const furnitureImagePart = bufferToGenerativePart(furnitureImage);
		parts.push(furnitureImagePart);
	}

	const contents = {
		parts,
	};

	const response = await ai.models.generateContent({
		model: model,
		contents,
		config: {
			responseModalities: [Modality.IMAGE],
		},
	});

	const firstPart = response.candidates?.[0]?.content?.parts?.[0];

	if (firstPart && firstPart.inlineData && firstPart.inlineData.data) {
		return firstPart.inlineData.data;
	} else {
		throw new Error('No image was generated by the API. The response may have been blocked.');
	}
};